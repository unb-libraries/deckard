api:
  host: '127.0.0.1'
  port: 5000
  llm:
    model:
      type: "llama"
      repo: "TheBloke/Nous-Hermes-Llama2-GGUF"
      filename: "nous-hermes-llama2-13b.Q6_K.gguf"
      max_response_tokens: 1024
      n_batch: 2048
      n_ctx: 4096
      n_gpu_layers: -1
      repeat_penalty: 1.176
      temperature: 0.71
      top_k: 40
      top_p: 0.1
      verbose: True
data_dir: '/home/core/llm/chatbot/data'
workflows:
  libpages:
    name: 'libpages'
    rag:
      name: 'libpages'
      stack:
        classname: 'RagStack'
      collectors:
        -
          name: 'Library Pages'
          classname: 'LibPagesCollector'
          output: 'collector/libpages/data/output'
      context:
        size: 4096
        max_vector_distance: 1.0
      chunker:
        classname: 'StandardChunker'
        size: 1024
        overlap: 128
      context_builder:
        classname: 'SimpleContextAggregator'
      context_database:
        classname: 'SQLite'
        name: 'libpages'
      embedding_database:
        classname: 'LanceDB'
        name: 'libpages'
      embedding_encoder:
        classname: 'SentenceTransformerEncoder'
        model: 'avsolatorio/GIST-large-Embedding-v0'
      query_processor:
        classname: 'StandardQueryProcessor'
      reranker:
        classname: 'SentenceTransformerEncoder'
        model: 'BAAI/bge-reranker-large'
        n_results: 5

