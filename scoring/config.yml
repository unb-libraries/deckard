evaluate:
  input: "test_input.spintax"
  report: "test_report.json"
  test_queries:
    - query: "What is the capital of France?"
      expected: "Sorry, this question doesn't seem to be answered"
    - query: "Where are the bathrooms?"
      expected: "Floor"
  output: "test_output.json"
  llm:
    model:
      type: "llama"
      repo: "TheBloke/Nous-Hermes-Llama2-GGUF"
      filename: "nous-hermes-llama2-13b.Q6_K.gguf"
      max_response_tokens: 1024
      n_batch: 2048
      n_ctx: 4096
      n_gpu_layers: -1
      repeat_penalty: 1.176
      temperature: 0.71
      top_k: 40
      top_p: 0.1
      verbose: True
  rag_configurations:
    -
      name: 'libpages'
      stack:
        class: 'RagStack'
      collectors:
        -
          name: 'Library Pages'
          class: 'LibPagesCollector'
          output: 'collector/libpages/data/output'
      context:
        size: 4096
        max_vector_distance: 1.0
      chunker:
        class: 'StandardChunker'
        size: 1024
        overlap: 128
      context_builder:
        class: 'SimpleContextAggregator'
      context_database:
        class: 'SQLite'
        name: 'libpages'
      embedding_database:
        class: 'LanceDB'
        name: 'libpages'
      embedding_encoder:
        class: 'SentenceTransformerEncoder'
        model: 'avsolatorio/GIST-large-Embedding-v0'
      query_processor:
        class: 'StandardQueryProcessor'
      reranker:
        class: 'SentenceTransformerEncoder'
        model: 'BAAI/bge-reranker-large'
        n_results: 5
