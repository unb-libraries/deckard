evaluate:
  input: "test_input.spintax"
  report: "test_report.json"
  test_queries:
    - query: "What is the capital of France?"
      expected: "Sorry, this question doesn't seem to be answered"
    - query: "Where are the bathrooms?"
      expected: "Floor"
    - query: "Who is the dean of UNB Libraries?"
      expected: "Balcom"
  output: "test_output.json"
  llm:
    model:
      type: "llama"
      repo: "TheBloke/Nous-Hermes-Llama2-GGUF"
      filename: "nous-hermes-llama2-13b.Q6_K.gguf"
      max_response_tokens: 1024
      n_batch: 2048
      n_ctx: 4096
      n_gpu_layers: -1
      repeat_penalty: 1.176
      temperature: 0.71
      top_k: 40
      top_p: 0.1
      verbose: True
